{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cb668d45-eec4-4365-a084-6ebe7572ea49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(name)s | %(message)s', datefmt='%H:%M:%S', force=True)\n",
    "logger = logging.getLogger(\"ETL_BRONZE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "388d08a1-1f49-49df-9231-f4cdb735eb56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Función de ingesta\n",
    "\n",
    "def procesar_a_bronze(ruta_origen, nombre_tabla, checkpoint, ruta_schema, formato):\n",
    "    logger.info(f\"Inicio: {nombre_tabla}, de {ruta_origen} a {checkpoint} (Schema: {ruta_schema})\")\n",
    "\n",
    "    try:\n",
    "        # Lectura\n",
    "        df_raw = (spark.readStream              # readStream es para leerlo dinámicamente y actualizar datos.\n",
    "            .format(\"cloudFiles\")               # Auto Loader\n",
    "            .option(\"cloudFiles.format\", formato) # csv o json\n",
    "            .option(\"pathGlobFilter\", f\"*.{formato}\") \n",
    "            .option(\"cloudFiles.inferColumnTypes\", \"true\")  # Spark escanea los archivos para adivinar tipos de datos\n",
    "            .option(\"cloudFiles.schemaEvolutionMode\", \"rescue\")\n",
    "            .option(\"cloudFiles.schemaLocation\", ruta_schema)\n",
    "            .option(\"header\", \"true\")           # Solo aplica para CSV \n",
    "            .option(\"multiline\", \"true\")        # Solo aplica para JSON \n",
    "            .load(ruta_origen)                  # De dónde leer\n",
    "        )\n",
    "\n",
    "        # Transformación\n",
    "        # Agregamos metadatos para leerlos después.\n",
    "        df_con_metadata = (df_raw\n",
    "            .withColumn(\"ingestion_timestamp\", current_timestamp()) # Fecha/Hora de procesamiento\n",
    "            .withColumn(\"source_filename\", col(\"_metadata.file_path\"))       # Nombre del archivo origen\n",
    "        )\n",
    "\n",
    "        # Escritura \n",
    "        query = (df_con_metadata.writeStream\n",
    "            .format(\"delta\")                    # Formato de almacenamiento final\n",
    "            .outputMode(\"append\")               # Solo agregamos datos nuevos\n",
    "            .option(\"checkpointLocation\", checkpoint) # Donde guardar el estado\n",
    "            .option(\"mergeSchema\", \"true\")      # Si aparecen columnas nuevas en el origen, agrégalas a la tabla\n",
    "            .trigger(availableNow=True)         # Procesa todo y detente\n",
    "            .table(nombre_tabla)                # Destino final\n",
    "        )\n",
    "\n",
    "        # Esperamos que el proceso termine\n",
    "        query.awaitTermination()\n",
    "        logger.info(f\"Terminado: {nombre_tabla}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error en {nombre_tabla}: {e}\")\n",
    "        logger.warning(\"Tabla salteada\")\n",
    "\n",
    "logger.info(\"Función de Ingesta preparada\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "common_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
