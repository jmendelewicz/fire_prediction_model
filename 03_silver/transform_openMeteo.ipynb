{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fed285-2e03-4cfc-8d06-9caa752e0006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Librerías \n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, from_json, explode, arrays_zip, to_timestamp, date_format, hour, expr, current_timestamp, lit, round, coalesce, regexp_replace, \n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, DoubleType\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3d61cf98-6a0b-4754-b608-ac3019378d97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logger para avisar\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s', force=True)\n",
    "logger = logging.getLogger(\"ETL_SILVER\")\n",
    "\n",
    "# Rutas de las tablas Bronze\n",
    "\n",
    "TABLE_BRONZE_CLIMA = \"fire_risk_project.01_bronze.bronze_open_meteo\"\n",
    "\n",
    "# Ruta tabla Silver\n",
    "\n",
    "TABLE_SILVER_CLIMA = \"fire_risk_project.02_silver.silver_open_meteo\"\n",
    "TABLE_SILVER_GRID = \"fire_risk_project.02_silver.silver_grid_master\" # Necesito transportar el id_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec7369fd-d134-41f8-9f9d-c22a5a83fddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transformación \n",
    "logger.info(f\"Procesando Silver: {TABLE_BRONZE_CLIMA} -> {TABLE_SILVER_CLIMA}\")\n",
    "\n",
    "df_clima_raw = spark.read.table(TABLE_BRONZE_CLIMA)\n",
    "\n",
    "# C. Desagrupado de filas por hora. Explode\n",
    "df_clima_exploded = (df_clima_raw\n",
    "    .select(\n",
    "        col(\"source_filename\"),\n",
    "        round(col(\"request_latitude\").cast(DoubleType()), 1).alias(\"latitude\"),\n",
    "        round(col(\"request_longitude\").cast(DoubleType()), 1).alias(\"longitude\"),\n",
    "        round(col(\"elevation_val\").cast(DoubleType()), 2).alias(\"elevation\"),\n",
    "        # EXPLODE + ARRAYS_ZIP\n",
    "        explode(arrays_zip(\n",
    "            # Al poner .alias aqui dentro, controlamos el nombre en el struct resultante\n",
    "            coalesce(col(\"hourly.time\"), col(\"hourly.date\")).alias(\"time_unified\"), \n",
    "            col(\"hourly.temperature_2m\"),\n",
    "            col(\"hourly.relative_humidity_2m\"),\n",
    "            col(\"hourly.vapour_pressure_deficit\"),\n",
    "            col(\"hourly.precipitation\"),\n",
    "            col(\"hourly.wind_speed_10m\"),\n",
    "            col(\"hourly.wind_direction_10m\"),\n",
    "            col(\"hourly.wind_gusts_10m\"),\n",
    "            col(\"hourly.et0_fao_evapotranspiration\"),\n",
    "            col(\"hourly.soil_moisture_0_to_7cm\"),\n",
    "            col(\"hourly.soil_moisture_28_to_100cm\"),\n",
    "            col(\"hourly.weather_code\"),\n",
    "            col(\"hourly.snow_depth\")\n",
    "        )).alias(\"zipped\")\n",
    "    )\n",
    "\n",
    "    # SELECCIÓN FINAL (Aquí corregimos el error de índices)\n",
    "    .select(\n",
    "        col(\"source_filename\"),\n",
    "        col(\"latitude\"),\n",
    "        col(\"longitude\"),\n",
    "        col(\"elevation\"),\n",
    "        # Accedemos por NOMBRE, no por número (excepto el que renombramos)\n",
    "        col(\"zipped.time_unified\").alias(\"timestamp_clima_str\"),\n",
    "        col(\"zipped.temperature_2m\"),            # Spark conservó el nombre original\n",
    "        col(\"zipped.relative_humidity_2m\"),\n",
    "        col(\"zipped.vapour_pressure_deficit\"),\n",
    "        col(\"zipped.precipitation\"),\n",
    "        col(\"zipped.wind_speed_10m\"),\n",
    "        col(\"zipped.wind_direction_10m\"),\n",
    "        col(\"zipped.wind_gusts_10m\"),\n",
    "        col(\"zipped.et0_fao_evapotranspiration\"),\n",
    "        col(\"zipped.soil_moisture_0_to_7cm\"),\n",
    "        col(\"zipped.soil_moisture_28_to_100cm\"),\n",
    "        col(\"zipped.weather_code\"),\n",
    "        col(\"zipped.snow_depth\")\n",
    "    )\n",
    "    \n",
    "    # Limpieza de fecha\n",
    "    .withColumn(\"timestamp_clima\", to_timestamp(regexp_replace(col(\"timestamp_clima_str\"), \"T\", \" \")))\n",
    "    .withColumn(\"fecha_join\", col(\"timestamp_clima\").cast(\"date\"))\n",
    "    .withColumn(\"hora_join\", hour(col(\"timestamp_clima\")))\n",
    "    .drop(\"timestamp_str\")\n",
    ")\n",
    "\n",
    "# Escritura\n",
    "df_clima_exploded.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(TABLE_SILVER_CLIMA)\n",
    "\n",
    "logger.info(f\"Tabla Silver Clima guardada en {TABLE_SILVER_CLIMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "579b767e-4a86-4926-afdd-c63af94e9ce1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769872921719}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- Agregamos el grid_id al frame\n",
    "CREATE OR REPLACE TABLE fire_risk_project.02_silver.silver_open_meteo AS\n",
    "SELECT w.*, g.grid_id FROM fire_risk_project.02_silver.silver_open_meteo w\n",
    "LEFT JOIN fire_risk_project.02_silver.silver_grid_master g\n",
    "ON w.latitude = g.latitude_centroid AND w.longitude = g.longitude_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f97ee02a-b0fc-45e8-806e-494f7f43e242",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769872930209}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificación \n",
    "\n",
    "df_clima_check = spark.read.table(TABLE_SILVER_CLIMA)\n",
    "display(df_clima_check.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcd16125-e66f-4f3b-b3e2-e771584e2b3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ordenamiento y limpieza del df\n",
    "\n",
    "df_clima_final = df_clima_check.select(\n",
    "    # 1. Claves Principales\n",
    "    col(\"grid_id\"),\n",
    "    col(\"timestamp_clima\"),\n",
    "    col(\"fecha_join\"),\n",
    "    col(\"hora_join\"),\n",
    "    \n",
    "    # 2. Features\n",
    "    col(\"temperature_2m\"),\n",
    "    col(\"relative_humidity_2m\"),\n",
    "    col(\"vapour_pressure_deficit\"),\n",
    "    col(\"precipitation\"),\n",
    "    col(\"wind_speed_10m\"),\n",
    "    col(\"wind_direction_10m\"),\n",
    "    col(\"wind_gusts_10m\"),\n",
    "    col(\"et0_fao_evapotranspiration\"),\n",
    "    col(\"soil_moisture_0_to_7cm\"),\n",
    "    col(\"soil_moisture_28_to_100cm\"),\n",
    "    col(\"weather_code\"),\n",
    "    col(\"snow_depth\"),\n",
    "    \n",
    "    # 3. Metadatos y Referencias\n",
    "    col(\"elevation\"),\n",
    "    col(\"latitude\"),\n",
    "    col(\"longitude\"),\n",
    "    col(\"source_filename\") \n",
    ")\n",
    "\n",
    "df_clima_final.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(TABLE_SILVER_CLIMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff3ab5b2-d4c7-4a92-aa42-e3fc65336740",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Z ordering para optimizar\n",
    "OPTIMIZE fire_risk_project.02_silver.silver_open_meteo ZORDER BY (grid_id, timestamp_clima);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5687de5-e8d6-4fdb-b212-22e997e23e4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Segunda verificación\n",
    "\n",
    "SELECT * FROM fire_risk_project.02_silver.silver_open_meteo LIMIT 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f96ed09e-e004-4a83-9fb2-9700a97ee350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "# Revisión final de contenidos de la tabla\n",
    "TABLE_TARGET = \"fire_risk_project.02_silver.silver_open_meteo\"\n",
    "EXPECTED_GRID_POINTS = 160\n",
    "EXPECTED_DAYS = 2191 \n",
    "EXPECTED_HOURS = 24\n",
    "EXPECTED_TOTAL_ROWS = EXPECTED_GRID_POINTS * EXPECTED_DAYS * EXPECTED_HOURS\n",
    "\n",
    "print(f\"INICIANDO AUDITORIA DE: {TABLE_TARGET}\")\n",
    "print(f\"OBJETIVOS: {EXPECTED_GRID_POINTS} puntos | {EXPECTED_DAYS} dias | {EXPECTED_HOURS} horas\")\n",
    "print(f\"TOTAL FILAS ESPERADAS: {EXPECTED_TOTAL_ROWS:,}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Lectura\n",
    "df = spark.read.table(TABLE_TARGET)\n",
    "\n",
    "# ESTRUCTURA Y VOLUMEN\n",
    "\n",
    "print(\"\\nVOLUMEN TOTAL\")\n",
    "total_rows_actual = df.count()\n",
    "diff = total_rows_actual - EXPECTED_TOTAL_ROWS\n",
    "\n",
    "if total_rows_actual == EXPECTED_TOTAL_ROWS:\n",
    "    print(f\"STATUS: OK. La tabla tiene exactamente {total_rows_actual:,} filas.\")\n",
    "else:\n",
    "    print(f\"STATUS: ALERTA. La tabla tiene {total_rows_actual:,} filas.\")\n",
    "    print(f\"Diferencia: {diff:+,} filas.\")\n",
    "\n",
    "# GEOGRAFIA\n",
    "print(\"\\nVALIDACION GEOGRAFICA\")\n",
    "puntos_unicos = df.select(\"latitude\", \"longitude\").distinct().count()\n",
    "print(f\"Cantidad de Puntos Geograficos Unicos: {puntos_unicos}\")\n",
    "\n",
    "if puntos_unicos == EXPECTED_GRID_POINTS:\n",
    "    print(f\"STATUS: OK. Coincide con los {EXPECTED_GRID_POINTS} puntos esperados.\")\n",
    "else:\n",
    "    print(f\"STATUS: ALERTA. Se encontraron {puntos_unicos} puntos.\")\n",
    "\n",
    "coords_nulas = df.filter(F.col(\"latitude\").isNull() | F.col(\"longitude\").isNull()).count()\n",
    "if coords_nulas == 0:\n",
    "    print(\"STATUS: OK. No hay coordenadas nulas.\")\n",
    "else:\n",
    "    print(f\"STATUS: ERROR CRITICO. Hay {coords_nulas} filas sin coordenadas.\")\n",
    "\n",
    "# CONTINUIDAD TEMPORAL (DIAS Y HORAS)\n",
    "print(\"\\nCONTINUIDAD TEMPORAL\")\n",
    "\n",
    "# A. Dias por Grid\n",
    "print(\"dias por Grid ID\")\n",
    "df_days_check = df.groupBy(\"grid_id\").agg(F.countDistinct(\"fecha_join\").alias(\"dias_totales\"))\n",
    "grids_bad = df_days_check.filter(F.col(\"dias_totales\") != EXPECTED_DAYS)\n",
    "count_grids_bad = grids_bad.count()\n",
    "\n",
    "if count_grids_bad == 0:\n",
    "    print(f\"STATUS: OK. Todos los puntos tienen {EXPECTED_DAYS} dias.\")\n",
    "else:\n",
    "    print(f\"STATUS: ALERTA. {count_grids_bad} puntos tienen dias incompletos.\")\n",
    "    display(grids_bad.limit(10))\n",
    "\n",
    "# B. Horas por Dia\n",
    "print(\"Horas por Dia\")\n",
    "df_hours_check = df.groupBy(\"grid_id\", \"fecha_join\").count().withColumnRenamed(\"count\", \"horas_registradas\")\n",
    "days_bad = df_hours_check.filter(F.col(\"horas_registradas\") != EXPECTED_HOURS)\n",
    "count_days_bad = days_bad.count()\n",
    "\n",
    "if count_days_bad == 0:\n",
    "    print(f\"STATUS: OK. Todos los dias tienen {EXPECTED_HOURS} horas.\")\n",
    "else:\n",
    "    print(f\"STATUS: ALERTA. {count_days_bad} combinaciones Grid-Dia no tienen 24 horas.\")\n",
    "    display(days_bad.limit(10))\n",
    "\n",
    "# FEATURES\n",
    "print(\"\\nFEATURES\")\n",
    "\n",
    "cols_exclude = [\"grid_id\", \"timestamp_clima\", \"fecha_join\", \"hora_join\", \"source_filename\"]\n",
    "feature_cols = [c for c in df.columns if c not in cols_exclude]\n",
    "\n",
    "# Calculo\n",
    "null_exprs = [F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in feature_cols]\n",
    "results_row = df.select(null_exprs).collect()[0]\n",
    "\n",
    "data = []\n",
    "for col_name in feature_cols:\n",
    "    null_count = results_row[col_name]\n",
    "    null_pct = (null_count / total_rows_actual) * 100\n",
    "    \n",
    "    status = \"OPTIMO\"\n",
    "    if null_pct > 0: status = \"ATENCION\"\n",
    "    if null_pct > 5: status = \"CRITICO (>5%)\"\n",
    "        \n",
    "    data.append({\n",
    "        \"Variable\": col_name,\n",
    "        \"Nulos_Cant\": null_count,\n",
    "        \"Nulos_Pct\": builtins.round(null_pct, 4),\n",
    "        \"Estado\": status\n",
    "    })\n",
    "\n",
    "pdf_features = pd.DataFrame(data).sort_values(by=\"Nulos_Cant\", ascending=False)\n",
    "display(pdf_features)\n",
    "\n",
    "# Conclusión\n",
    "total_nulls = pdf_features[\"Nulos_Cant\"].sum()\n",
    "if total_nulls == 0:\n",
    "    print(\"CONCLUSION: DATASET COMPLETO. Listo para usar.\")\n",
    "else:\n",
    "    print(f\"CONCLUSION: SE DETECTARON {total_nulls} NULOS. Revisar tabla anterior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5428302e-e812-4724-b11d-20c9ef839132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finalizado el proceso tranformación de datos para datos Open Meteo"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6603779733367785,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_openMeteo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
