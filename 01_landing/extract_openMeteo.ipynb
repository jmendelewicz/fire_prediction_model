{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0285f26e-4b2c-4139-b687-3f5929135da2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Librerías\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from datetime import datetime, date, timedelta\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5919ee2a-3587-4e85-a170-acebcc249730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logger para avisar\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s', datefmt='%H:%M:%S', force=True)\n",
    "logger = logging.getLogger(\"ETL_VOLUMES\")\n",
    "\n",
    "# Paths y carpetas para OpenMeteo\n",
    "\n",
    "BASE_VOLUME_PATH_METEO = \"/Volumes/fire_risk_project/00_landing/meteo_files\"\n",
    "PATH_CLIMA = os.path.join(BASE_VOLUME_PATH_METEO, \"open_meteo\")\n",
    "\n",
    "# Directorios\n",
    "\n",
    "try:\n",
    "    os.makedirs(PATH_CLIMA, exist_ok=True)\n",
    "    logger.info(\"Carpetas configuradas\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Aviso: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72ebf19c-9bc5-4630-b8f8-556849824ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parametros necesarios para la extracción OpenMeteo\n",
    "\n",
    "VARIABLES_CLIMA = [\n",
    "    \"temperature_2m\", \n",
    "    \"relative_humidity_2m\", \n",
    "    \"vapour_pressure_deficit\", \n",
    "    \"precipitation\", \n",
    "    \"wind_speed_10m\", \n",
    "    \"wind_direction_10m\", \n",
    "    \"wind_gusts_10m\", \n",
    "    \"et0_fao_evapotranspiration\", \n",
    "    \"soil_moisture_0_to_7cm\", \n",
    "    \"soil_moisture_28_to_100cm\", \n",
    "    \"weather_code\", \n",
    "    \"snow_depth\"\n",
    "]\n",
    "\n",
    "# Configura el caché y los reintentos \n",
    "\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afac76b7-8a05-4a14-8331-20997fac7ccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def etl_clima(year_start, year_end):\n",
    "    \n",
    "    df_grid = spark.table(\"fire_risk_project.00_landing.aux_grid_master\").toPandas()\n",
    "    \n",
    "    pendientes = []\n",
    "    for index, row in df_grid.iterrows():\n",
    "        cell_id = row['cell_id']\n",
    "        file_name = f\"weather_{cell_id}.json\"\n",
    "        final_path = os.path.join(PATH_CLIMA, file_name)\n",
    "        if not os.path.exists(final_path):\n",
    "            pendientes.append(row)\n",
    "            \n",
    "    if not pendientes:\n",
    "        logger.info(\"Todos los archivos ya existen. Nada que descargar.\")\n",
    "        return\n",
    "\n",
    "    logger.info(f\"Descargando {len(pendientes)} puntos\")\n",
    "    \n",
    "    df_pendientes = pd.DataFrame(pendientes)\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    \n",
    "    # Mantenemos lotes de 5, el número más manejable\n",
    "    CHUNK_SIZE = 5\n",
    "    \n",
    "    for i in range(0, len(df_pendientes), CHUNK_SIZE):\n",
    "        chunk = df_pendientes.iloc[i:i+CHUNK_SIZE]\n",
    "        \n",
    "        lats = chunk['latitude'].tolist()\n",
    "        lons = chunk['longitude'].tolist()\n",
    "        ids = chunk['cell_id'].tolist()\n",
    "        \n",
    "        params = {\n",
    "            \"latitude\": lats,\n",
    "            \"longitude\": lons,\n",
    "            \"start_date\": year_start,\n",
    "            \"end_date\": year_end,\n",
    "            \"hourly\": VARIABLES_CLIMA\n",
    "        }\n",
    "        \n",
    "        lote_procesado = False\n",
    "        intentos_lote = 0\n",
    "        \n",
    "        while not lote_procesado and intentos_lote < 5:\n",
    "            try:\n",
    "                # Llamada a la API\n",
    "                responses = openmeteo.weather_api(url, params=params)\n",
    "                \n",
    "                for idx, response in enumerate(responses):\n",
    "                    cell_id = ids[idx]\n",
    "                    lat = response.Latitude()\n",
    "                    lon = response.Longitude()\n",
    "                    elev = response.Elevation()\n",
    "                    \n",
    "                    hourly = response.Hourly()\n",
    "                    hourly_data = {\n",
    "                        \"date\": pd.date_range(\n",
    "                            start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "                            end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "                            freq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "                            inclusive = \"left\"\n",
    "                        ).astype(str).tolist()\n",
    "                    }\n",
    "                    \n",
    "                    for var_idx, var_name in enumerate(VARIABLES_CLIMA):\n",
    "                        var_obj = hourly.Variables(var_idx)\n",
    "                        if var_obj:\n",
    "                            values = var_obj.ValuesAsNumpy()\n",
    "                            hourly_data[var_name] = [None if np.isnan(x) else float(x) for x in values]\n",
    "                    \n",
    "                    final_data = {\n",
    "                        \"cell_id\": cell_id,\n",
    "                        \"request_latitude\": lats[idx],\n",
    "                        \"request_longitude\": lons[idx],\n",
    "                        \"elevation_val\": elev,\n",
    "                        \"hourly\": hourly_data\n",
    "                    }\n",
    "                    \n",
    "                    file_name = f\"weather_{cell_id}.json\"\n",
    "                    final_path = os.path.join(PATH_CLIMA, file_name)\n",
    "                    with open(final_path, \"w\") as f:\n",
    "                        json.dump(final_data, f)\n",
    "                \n",
    "                logger.info(f\"Lote {i//CHUNK_SIZE + 1} procesado correctamente.\")\n",
    "                lote_procesado = True \n",
    "                time.sleep(5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                # Si el error es por límite de minuto, esperamos 65 segundos y reintentamos\n",
    "                if \"Minutely API request limit\" in error_msg or \"429\" in error_msg:\n",
    "                    logger.warning(f\"Límite por minuto alcanzado en archivo {i}, Lote {i//CHUNK_SIZE + 1}. Reintentando en 65 segundos...\")\n",
    "                    time.sleep(65)\n",
    "                    intentos_lote += 1\n",
    "                else:\n",
    "                    logger.error(f\"Error en lote {i}: {e}\")\n",
    "                    break \n",
    "\n",
    "logger.info(\"Función etl_clima lista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "939c6b1a-79b8-427b-b783-e020d81b9b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ejecución para OpenMeteo\n",
    "\n",
    "etl_clima(\"2020-01-01\", \"2025-12-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55750fdd-c041-4b79-a034-39a3fc2900e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificación \n",
    "\n",
    "try:\n",
    "    if os.path.exists(PATH_CLIMA):\n",
    "        # Filtramos solo .json \n",
    "        archivos_clima = [f for f in os.listdir(PATH_CLIMA) if f.endswith('.json')]\n",
    "        archivos_clima.sort()\n",
    "        count_clima = len(archivos_clima)\n",
    "        \n",
    "        total_esperado = 160 # Tamaño de la grilla\n",
    "        progreso = (count_clima / total_esperado) * 100\n",
    "        \n",
    "        print(f\"Total : {count_clima} ({progreso:.1f}%)\")\n",
    "        \n",
    "        if count_clima > 0:\n",
    "            print(f\"Primer celda: {archivos_clima[0]}\") \n",
    "            print(f\"Última celda: {archivos_clima[-1]}\") \n",
    "            \n",
    "            # Leemos el último .json para verificar estructura nueva\n",
    "            ultimo_clima = os.path.join(PATH_CLIMA, archivos_clima[-1])\n",
    "            with open(ultimo_clima, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                keys = list(data.get(\"hourly\", {}).keys())\n",
    "                \n",
    "                print(f\"\\nEstructura: {archivos_clima[-1]}\")\n",
    "                print(f\"Variables climáticas: {len(keys)}\")\n",
    "                print(f\"{keys[:4]}...\") # Mostramos 4 para ver si están de verdad\n",
    "        else:\n",
    "            print(\"No hay archivos .json.\")\n",
    "    else:\n",
    "        print(\"No existe el directorio.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error en la verificación OpenMeteo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0532bd57-196f-4f35-8a88-4ab9a9d298a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finalizado proceso de extracción de OpenMeteo por grilla para el período 2020-2025"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4820404558845737,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "extract_openMeteo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
